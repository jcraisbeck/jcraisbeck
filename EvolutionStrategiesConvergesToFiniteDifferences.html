<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Evolution Strategies Converges to Finite Differences</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="inner">

							<!-- Logo -->
								<a href="index.html" class="logo">
									<span class="symbol"><img src="images/logo.svg" alt="" /></span><span class="title">Paper</span>
								</a>

							<!-- Nav -->
								<nav>
									<ul>
										<li><a href="#menu">Menu</a></li>
									</ul>
								</nav>

						</div>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<h2>Menu</h2>
						<ul>
							<li><a href="index.html">Home</a></li>
							<li><a href="biography.html">Biography</a></li>
							<li><a href="MathematicalReinforcementLearning.html">Mathematical Reinforcement Learning</a></li>
							<li><a href="ResearchStatement.html">Research Statement</a></li>
							<li><a href="https://all.cs.umass.edu">Autonomous Learning Laboratory</a></li>
							<li><a href="https://mattwallen.com">Collaborator: Matthew Allen</a></li>
							<li><a href="https://curriculum-vitae.piofn.com">Curriculum Vitae</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						<div class="inner">
							<h1>Evolution Strategies Converges to Finite Differences</h1>
							<p><b>I am in the process of rewriting this paper.</b><br>
							This paper investigates the between the <a href="https://openai.com/blog/evolution-strategies/">Evolution Strategies method</a> applied by a team lead by <a href="https://research.google/people/106222/">Tim Salimans</a> at <a href="https://openai.com">OpenAI</a> and the class of algorithms which are known as "finite differences gradient approximators". This subject has already been investigated by <a href="https://arxiv.org/abs/1712.06564">several</a> <a href=https://dl.acm.org/doi/abs/10.1145/3205455.3205474>groups</a>. In the paper we prove that as the dimension of the object being optimized increases, Evolution Strategies converges to a finite differences method. Establishing this result requires several changes in the standard understanding of a "finite differences" method, which are explored in greater depth in the coming version of the paper. In brief, we contend that the success of Salimans' Evolution Strategies should be interpreted as a coup for traditional finite differences, rather than a success of evolutionary or genetic methods.</p>
							<p><b>Abstract:</b> Since the debut of Evolution Strategies (ES) as a tool for Reinforcement Learning by Salimans et al. 2017, there has been interest in determining the exact relationship between the Evolution Strategies gradient and the gradient of a similar class of algorithms, Finite Differences (FD).(Zhang et al. 2017, Lehman et al. 2018) Several investigations into the subject have been performed, investigating the formal motivational differences(Lehman et al. 2018) between ES and FD, as well as the differences in a standard benchmark problem in Machine Learning, the MNIST classification problem(Zhang et al. 2017). This paper proves that while the gradients are different, they converge as the dimension of the vector under optimization increases. </p>
							<p><a href="https://arxiv.org/abs/2001.01684">arXiv</a></p>
						</div>
					</div>
		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
